7
Learning How to Discover
CAMBRIDGE, MASSACHUSETTS (MAY 15, 2012)
It's been more than five decades since you first wrote about universal grammar, the idea of an inborn capacity in every human brain that allows a child to learn language. What are some of the more recent developments in the field?
Well, that gets technical, but there's very exciting work going on refining the proposed principles of universal grammar. The concept is widely misunderstood in the media and in public discussions. Universal grammar is something different: it is not a set of universal observations about language. In fact, there are interesting generalizations about language that are worth studying, but universal grammar is the study of the genetic basis for language, the genetic basis of the language faculty. There can't be any serious doubt that something like that exists. Otherwise an infant couldn't reflexively acquire language from whatever complex data is around. So that's not controversial. The only question is what the genetic basis of the language faculty is.
Here there are some things that we can be pretty confident about. For one thing, it doesn't appear that there's any detectable variation among humans. They all seem to have the same capacity. There are individual differences, as there are with everything, but no real group differences—except maybe way at the margins. So that means, for example, if an infant from a Papua New Guinea tribe that hasn't had contact with other humans for thirty thousand years comes to Boulder, Colorado, it will speak like any kid in Colorado, because all children have the same language capacity. And the converse is true. This is distinctly human. There is nothing remotely like it among other organisms. What explains this?
Well, if you go back fifty years, the proposals that were made when this topic came on the agenda were quite complex. In order just to account for the descriptive facts that you saw in many different languages, it seemed necessary to assume that universal grammar permitted highly intricate mechanisms, varying a lot from language to language, because languages looked very different from one another.
Over the past fifty to sixty years, one of the most significant developments, I think, is a steady move, continuing today, toward trying to reduce and refine the assumptions so that they maintain or even expand their explanatory power for particular languages but become more feasible with regard to other conditions that the answer must meet.
Whatever it is in our brain that generates language developed quite recently in evolutionary time, presumably within the last one hundred thousand years. Something very significant happened, which is presumably the source of human creative endeavor in a wide range of fields: creative arts, tool making, complex social structures. Paleoanthropologists sometimes call it "the great leap forward." It's generally assumed, plausibly, that this change had to do with the emergence of language, for which there's no real evidence before in human history or in any other species. Whatever happened had to be pretty simple, because that's a very short time span for evolutionary changes to take place.
The goal of the study of universal grammar is to try to show that there is indeed something quite simple that can meet these various conditions. A plausible theory has to account for the variety of languages and the detail that you see in the surface study of languages—and, at the same time, be simple enough to explain how language could have emerged very quickly, through some small mutation of the brain, or something like that. There has been a lot of progress toward that goal and, in a parallel effort, to try to account for the apparent variability of languages by showing that, in fact, the perceived differences are superficial. The seeming variability has to do with minor changes in a few of the structural principles that are fixed.
Discoveries in biology have encouraged this line of thinking. If you go back to the late 1970s, François Jacob argued that it could well turn out—and probably is true—that the differences between species, let's say an elephant and a fly, could be traceable to minor changes in the regulatory circuits of the genetic system, the genes that determine what other genes do in particular places. He shared the Nobel Prize for early work on this topic.
It looks like something similar may be true of language. There's now work on an extraordinarily broad range of typologically different languages—and, more and more, it looks like that. There's plenty of work to do, but a lot of this research falls into place in ways that were unimaginable thirty or forty years ago.
In biology it was plausible quite recently to claim that organisms can vary virtually without limit and that each one has to be studied on its own. Nowadays that has changed so radically that serious biologists propose that there's basically one multicellular animal—the "universal genome"—and that the genomes of all the multicellular animals that have developed since the Cambrian explosion half a billion years ago are just modifications of a single pattern. This thesis hasn't been proven, but it is taken seriously.
Something similar is going on, I think, in the study of language. Actually, I should make it clear that this is a minority view, if you count noses. Most of the work on language doesn't even comprehend these developments or take them seriously.
Is the acquisition of language biological?
I don't see how anyone could doubt that. Just consider a newborn infant. The newborn is barraged by all kinds of stimuli, what William James famously called "one great blooming, buzzing confusion." If you put, say, a chimpanzee or a kitten or a songbird in that environment, it can only pick out what's related to its own genetic capacities. A songbird will pick out a melody of its species or something from all this mass because it's designed to do that, but it can't pick out anything that's relevant to human language. On the other hand, an infant does. The infant instantly picks language-related data out of this mass of confusion. In fact, we now know that this goes on even in the uterus. Newborn infants can detect properties of their mother's language as distinct from certain—not all, but certain—other languages.
And then comes a very steady progression of acquisition of complex knowledge, most of it completely reflexive. Teaching doesn't make any difference. An infant is just picking it out of the environment. And it happens very fast, in a very regular fashion. A lot is known about this process. By about six months, the infant has already analyzed what's called the prosodic structure of the language, stress, pitch—languages differ that way—and has sort of picked out the language of its mother or whatever it hears, its mother and its peers. By about nine months, roughly, the child has picked out the relevant sound structure of the language. So when we listen to Japanese speakers speaking English, we notice that, from our point of view, they confuse "r" and "l," meaning they don't know the distinction. That's already fixed in an infant's mind by less than a year old.
Words are learned very early, and, if you look at the meaning of a word with any care, it's extremely intricate. But children pick up words often after only one exposure, which means the structure has got to be in the mind already. Something is being tagged with a particular sound. By, say, two years, there's pretty good evidence that the children have mastered the rudiments of the language. They may just produce one-word or two-word sentences, but there's now experimental and other evidence that a lot more is in there. By three or four, a normal child will have extensive language capacity.
Either this is a miracle or it's biologically driven. There are just no other choices. There are attempts to claim that language acquisition is a matter of pattern recognition or memorization, but even a superficial look at those proposals shows that they collapse very quickly. It doesn't mean that they're not being pursued. In fact, those lines of inquiry are very popular. In my view, though, they're just an utter waste of time.
There are some very strange ideas out there. For instance, a lot of quite fashionable work claims that children acquire language because humans have the capacity to understand the perspective of another person, according to what's called theory of mind. The capacity to tell that another person is intending to do something develops in normal children at roughly age three or four. But, in fact, if you look at the autism spectrum, one of the classic syndromes is failure to develop theory of mind. That's why autistic kids, or adults for that matter, don't seem to understand what other people's intentions are. Nevertheless, their language can be absolutely perfect. Furthermore, this capacity to understand the intention of others develops long after the child has mastered almost all the basic character of the language, maybe all of it. So that can't be the explanation.
There are other proposals which also just can't be true, but are still pursued very actively. You read about them in the press, just as you read things about other organisms having language capacity. There's a lot of mythology about language, which is very popular. I really don't want to sound too dismissive, but I feel dismissive. I think these ideas can't be considered seriously.
Whatever our language faculty is, humans develop it very quickly, on very little data. In some domains, like the meaning of expressions, there's virtually no data. Nevertheless it's picked up very quickly and very precisely, in complex ways. Even with sound structure, where there's a lot of data—there are sounds around, you hear them—it's still a regular process and it's distinctively human. Which is striking, because it's now known that the auditory systems of higher apes, say chimpanzees, appear to be very similar to the human auditory system, even picking out the kinds of sounds that play a distinctive role in human language. Nevertheless, it's just noise for the ape—they can't do anything with it. They don't have the analytical capacities, whatever they are.
What's the biological basis for these human capacities? That's a very difficult problem. We know a lot, for example, about the human visual system, partly through experimentation. At the neural level, we know about it primarily from invasive experiments with other species. If you conduct invasive experiments on other mammals, cats or monkeys, you can find the actual neurons in the visual system that are responding to a light moving in a certain direction. But you can't do that with language. There is no comparative evidence, because other species don't have the capacity and you can't do invasive experiments with humans. Therefore, you have to find much more complex and sophisticated ways to try to tease out some evidence about how the brain is handling all this. There's been some progress in this extremely difficult problem, but it's very far from yielding the kind of information you could get from experimentation.
If you could experiment with humans, say, isolating a child and controlling carefully the data presented to it, you could learn quite a lot about language. But obviously you can't do that. The closest we've come is looking at children with sensory deprivation, blind children, for example. What you find is pretty amazing. For example, a very careful study of the language of the blind found that the blind understand the visual words look, see, glare, gaze, and so on quite precisely, even though they have zero visual experience. That's astonishing. The most extreme case is actually material that my wife, Carol, worked on, adults who were both deaf and blind. There are techniques for teaching language to the deaf-blind. Actually, Helen Keller, who is the most famous case, invented them for herself. It involves putting your hand on somebody's face, with your fingers on the cheeks and thumb on the vocal cords. You get some data from that, which is extremely limited. But that's the data available to the deaf-blind, and they have pretty remarkable language capacity. Helen Keller was incredible, a great writer, very lucid. She's an extreme case.
Carol did a study here at MIT. She found in working with people with sensory deprivation that they achieved pretty remarkable language capacity. You have to do quite subtle experiments to find things they don't know. In fact, they managed to get along by themselves. The primary subject, the one most advanced, was a man who was a tool and die maker, I think. He worked in a factory somewhere in the Midwest. He lived with his wife, who was also deaf-blind, but they found ways to communicate with buzzers in the house and things that you could touch that vibrated. He was able to get from his house to Boston for the experiments by himself. He carried a little card which said on it, "I am deaf-blind. May I put my hand on your face?" so, if he got lost, if somebody would let him do that, he could communicate with them. And he lived a pretty normal life.
One very striking fact was that all of the cases that succeeded were people who had lost their sight and hearing at about eighteen months old or older—it was primarily through spinal meningitis in those days. People who were younger than that when they became deaf-blind never learned language. There weren't enough cases to actually prove anything, so the results of the study were never published, but this was a pretty general result. Helen Keller fits. She was twenty months old when she lost her sight and hearing. It suggests, at least, that by eighteen or twenty months, a tremendous amount of language is already known. It can't be exhibited but it's in there somewhere, and can possibly be teased out later.
It's known that the ability to acquire language starts decreasing rather sharply by about the mid-teens.
That's descriptively correct, although, again, it's not 100 percent correct. There is individual variation. There are individuals who can pick up a language virtually natively at a much later age. Actually, one of them was in our department. Kenneth Hale, one of the great modern linguists, could learn a language like a baby. We used to tease him that he just never matured.
That's an exception?
Yes. By and large, what you said is true. The basis is not really known, but there are some thoughts about it. One thing we know is that, from the very beginning, brain development entails losing capacities. Your brain is originally set up so that it can acquire anything that a human can acquire. In the case of language, say, it's set up so that you can acquire Japanese, Bantu, Mohawk, English, whatever. Over time that declines. In some cases, it declines even after a few months of age. What's happening across all cognitive capacities, not only in the case of language, is that synaptic connections, connections inside the brain, are being lost. The brain is being simplified, it's being refined. Certain things are becoming more effective, other things are just gone. There's apparently a lot of synaptic loss around the period of puberty or shortly beforehand, and that could be relevant.
I attended one of your seminars in linguistics here at MIT a few years ago, and I was struck by a couple of things. First of all, I was one of the few non-Asians in your class. It was mostly South Asians and East Asians. But the other thing was the extent to which math was involved. You were constantly writing formulas on the blackboard.
We should be clear about that. It's not deep mathematics. It's not like proving hard theorems in algebraic topology or something. But there's good reason why some sophistication in mathematics is at least advantageous, maybe necessary, for advanced work. The basic reason is that language is a computational system. So whatever else it is, the capacity we're both using and sharing is based on a computational procedure that forms an infinite array of hierarchically structured expressions.
A lot of people conflate linguistics with the ability to speak many languages. So in your case, people think, Oh, Chomsky, he must know ten or twelve languages. But in fact linguistics is another universe. Explain why the study of language is important. Clearly, you're animated by it. You've devoted most of your life to it.
I should say, sometimes there's a distinction made between languist and linguist. A languist is somebody who can speak a lot of languages. A linguist is somebody who is interested in the nature of language.
Why is it interesting? Think about the picture that I presented before, which I think is fairly uncontroversial. At some time in the very recent past, from an evolutionary point of view, something quite dramatic happened in the human lineage. Humans developed what we now have: a very wide range of creative capacities that are unknown in the previous record or among other animals. There is no analogue to them. That's the core of human cognitive, moral, aesthetic nature—and right at the heart of it was the emergence of language.
In fact, it's very likely that language was the lever by which the other capacities develop. In fact, other capacities may just be piggybacking off language. It's possible that our arithmetical capacities and—quite likely—our moral capacities developed in a comparable way, maybe drawing from the analytical, computational mechanisms that yield language in all of its rich complexity. To the extent that we understand these other things, which is not very much, it seems that they're using the same or similar computational mechanisms.
Clearly, culture influences and shapes language, even if it doesn't determine it.
That's a common comment, but it's almost meaningless. What's culture? Culture is just a general term for everything that goes on. Yes, sure, everything that goes on influences language.
If we're, let's say, in a violent environment, doesn't that shape the vocabulary? Wouldn't that lead us to talk about "epicenter" and "Ground Zero" and "terrorism" and other terms in the lexicon of violence?
Sure, there's an effect on lexical choices. But that's peripheral to language. You could take any language that exists and add those concepts to it—a fairly trivial matter. But we don't know anything really about the effects of culture on lexical choices. In my view, it's unlikely cultural environments meaningfully affect the nature of language. Take, say, English, and trace it back to earlier periods. English was different in Chaucer's time or King Arthur's time, but the language hasn't fundamentally changed, the vocabulary has. Not long ago Japan was a feudal society, and now it's a modern technological society. The Japanese language has changed, of course, but not in ways that reflect those changes. And if Japan went back to being a feudal society, the language wouldn't change much either.
Vocabulary does, of course. You talk about different things. For example, the tribe in Papua New Guinea that I mentioned before wouldn't have a word for computer. But again that's fairly trivial. You could add the word for computer. Ken Hale's work from the 1970s on this question is quite instructive. He was a specialist on Australian aboriginal languages, and he showed that many of these languages appear to lack elements that are common in the modern Indo-European languages. For example, they don't have words for numbers or colors and they don't have embedded relative clauses. He studied this topic in depth and showed that these gaps were quite superficial. So, for example, the tribes he was working with didn't have numbers, but they had absolutely no problem counting. As soon as they moved into a market society and had to deal with counting, they just used other mechanisms. Instead of number words, they would use their hand for five, two hands for ten. They didn't have color words. Maybe they just had black and white, which apparently every language has. But they used expressions such as like blood for what we would call red.
Hale's conclusion was that languages are basically all the same. There are gaps. We have many gaps in our language that other languages don't have, and conversely, they have gaps that we don't have. It's a little bit like what I said before about whether organisms vary infinitely or whether there's a universal genome. If you take a look at organisms, they look wildly different, so it was quite natural to assume fifty years ago that they vary in every possible way. The more we have learned, the less plausible that seems. There's a lot of conservation of genes. Yeasts have a genetic structure not all that different from ours in many ways, although yeasts look very different from us. But there are fundamental biological processes that just show up differently on the surface and seem different until you understand them. And something like that appears to be the case with language. Ken's work on this topic is the most sophisticated. There's a lot of popular discussion about "similar data" now, but most of it is extremely superficial and ignorant. In fact, there's almost nothing that's discussed now that he didn't talk about in a much more serious way forty years ago.
People who just read your books don't realize, I think, that you have a mischievous side. At the linguistics seminar I attended, I told you that I had to leave early, and you told me to shake my head back and forth, as I was leaving the classroom, and say, "I don't know what that guy Chomsky is talking about. This is just a lot of nonsense."
That's what this all sounds like if you don't have the right background. There's this commonsense idea: when I talk, I don't think about any of those things linguists are talking about. I don't have any of these structures in my head. So how can they be real? This kind of deep anti-intellectualism, an insistence on ignorance, runs through a large part of the culture. With discussions of language, it's almost ubiquitous.
You could say the same thing about vision. So, for example, one of the most interesting things known about the visual system is that it has core properties that interpret complex reality in terms of rigid objects in motion. In fact, you almost never see rigid objects in motion. It's not part of experience. But that's the way the visual system works.
Take, say, a baseball game. When you interpret an outfielder catching a fly ball, you don't and he doesn't introspect into the method by which he's doing that, which is a pretty remarkable thing. Like how does an outfielder know instantaneously where to run as soon as the crack of a bat takes place? It turns out that's a pretty sophisticated calculation and pretty well understood. But you can't introspect into it. In fact, if you did, you would fall on your face and you wouldn't catch the ball. It's sort of like trying to introspect on how you digest your food. You can't do it. People feel that they ought to be able to do it in cognitive domains because we're partially conscious—at least, we have a consciousness of some of the superficial aspects of our actions. For example, you know you're running to catch a ball. But consciousness of superficial aspects of our activity doesn't give you any insight into the internal computations of the brain that allow these actions to take place.
You've said many times that your linguistics and political work don't intersect in any way. But what is striking is your syncretic power, your ability to gather very disparate information together into a coherent picture.
I think anybody can do it. I have no special talents in that regard. There are some talents, if you like, that are useful for the sciences—or for the study of, say, international affairs or personal relations. One important one that everybody has, if they feel like using it, is just the ability to be puzzled. Why do things happen this way? If you look at the history of modern science, that ability has yielded dramatic results at many points. Albert Einstein was interested in the question of what the world would look like if you were traveling at the speed of light. He was puzzled by that. Out of that came important insights.
Modern science really developed from a willingness to question things that had always been taken for granted. If I have a cup in my hand full of boiling water, and I let go with both hands, the steam rises and the cup falls. Why? Well, for millennia there was a good answer from the best scientists: the cup and steam are both going to their natural place. The natural place of the steam is up there, and the natural place for the cup is down there. End of discussion. But Galileo and others decided that they were puzzled by this event. Why does this happen? And as soon as they started to be puzzled, the question turned out to be significant. As soon as you look carefully, you find that all your intuitions are wrong. Our intuition is that a heavy ball and a light ball will fall at different rates. They don't. In fact, just about all intuitions are wrong. Modern science comes out of that understanding.
When you go to the social and political domain, there are certain doctrines that are just taken for granted, like things go to their natural place. For example, the United States is a benign actor. It makes mistakes, but its leaders are trying to do good in the world. People make mistakes, it's a complicated world, but we're promoting democracy. We love democracy. If you don't accept these dogmas, you're just not part of the discourse. That's true of ordinary discourse. That's true of professional scholarship to a remarkable degree. That's true of the media overwhelmingly. You can find case after case.
Take a look at an article in the New York Times by Bill Keller, the paper's former executive editor, on our inherent benign character. He points out there are very troubling exceptions: we supported and are supporting serious atrocities in Bahrain, and we don't do anything about the most reactionary state in the region, Saudi Arabia. He says these exceptions are troubling because they don't fit our general nature. That's about at the level of "things go to their natural place."
It doesn't take much brilliance to recognize that this is not schizophrenia and there's nothing surprising about it. It's exactly the way great powers operate. They have domestic power structures that determine policy. There are a lot of other factors, but they're not overwhelmingly significant. If you look at the goals and intentions of political elites, everything falls into place. Of course, if you take that stand, you're excluded from polite discourse—just as, incidentally, Galileo was. He couldn't convince the funders, the aristocrats, that any of his ideas made any sense because they were so counter to common sense. He suffered for it under the Inquisition, as dissidents commonly do suffer. He was forced to renounce formally everything he believed. Legend has it that under his breath he said, "Eppur si muove" ("And yet it moves"). Whether that's true or not, I don't know.
Almost every society I've ever heard of, back to the earliest records, treats those we call dissidents, people who depart from the established consensus, pretty harshly. How harshly depends on the society. Another interesting thing about our culture is that we are very outraged by the harsh treatment of dissidents in enemy states. So the treatment of, say, Václav Havel or Aleksandr Solzhenitsyn is considered an utter outrage quite rightly. You can find countless articles in the New York Times about the horrible way in which dissidents are treated elsewhere. But, if you look at the facts, dissidents in U.S. domains are treated far more harshly. So you can read in the standard Cambridge History of the Cold War that since 1960 the record of torture, assassination, and other atrocities in U.S. domains vastly exceeds anything in the Soviet and Russian domains. It's obviously true. So yes, Havel was imprisoned. Very bad. Six Jesuit intellectuals in El Salvador had their heads blown off. Worse. In fact, nobody even knows their names. Everyone knows the names of the Eastern European dissidents. Try to find somebody who knows the names of the dissidents in, say, El Salvador or Colombia, anywhere in U.S. domains.
A lot of what is called the new media, Facebook and Twitter, plus what are called handheld devices, iPads and tablets and the like, are creating greater social atomization and isolation. I've had the experience of being in a restaurant and everyone is looking down at their iPhone, sending messages and checking e-mail. What impact might this have on society?
I'm really not part of this culture at all, so I'm just observing it from outside, and not with very much intensity or understanding. But my impression is that the people participating in it, the young people participating in it have a feeling of intimacy and interaction. But I have to say, it reminds me of a close friend of mine as a kid who had a little booklet in which he wrote the names of all his friends. He used to boast that he had two hundred friends, which meant he had no friends, because you don't have two hundred friends. And I suspect that it's similar to that. If you have a whole bunch of friends on Facebook or whatever, it almost has to be pretty superficial. If that's your outlet to the world, there's something really missing in your life.
In fact, one of the significant aspects of the Occupy movements, maybe their most significant aspect, is the way they're overcoming that by creating real communities of people who interact, who have associations and bonds and help each other, support each other, really talk to each other freely, something which is very much missing in the whole society. You have it in bits and pieces, of course. But there has been, I think, a conscious effort to atomize the society for a long time, to break people up, to break down what are called secondary associations in the sociological literature: groups that interact and construct spaces in which people can formulate ideas, test them, begin to understand human relations and learn what it means to cooperate with each other. Unions were one of the major examples of this, and that's part of the reason for their generally very progressive impact on society. And, of course, they've been a major target of attack, I think partially for that reason.
The whole concept of social solidarity is considered very threatening by concentrated power. That's true in any system, and is very striking in ours.
Although the social media are undoubtedly invaluable for organizing and keeping some connections alive, I think they contribute to atomization. That's my superficial impression from outside.
Let's talk about education in a capitalist society. You've taught for many years. One of your strongest influences was the educator John Dewey, whom you've described as "one of the relics of the Enlightenment classical liberal tradition." 
One of the real achievements of the United States is that it pioneered mass public education, not just elite education for the few and maybe some vocational training, if anything, for the many. The opening of land-grant colleges and general schools in the nineteenth century was a very significant development. But if you look back, the reasons for this were complex. Actually, one of them was discussed by Ralph Waldo Emerson. He was struck by the fact that business elites—he didn't use that term—were interested in public education. He speculated that the reason was that "you must educate them to keep them from our throats." In other words, the mass of the population is getting more rights, and unless they're properly educated, they may come after us.
There's a corollary to this. If you have a free education that engenders creativity and independence, the way of looking at the world that we were talking about before, people are going to come for your throat because they won't want to be governed. So yes, let's have a mass education system, but of a particular kind, one that inculcates obedience, subordination, acceptance of authority, acceptance of doctrine. One that doesn't raise too many questions. Deweyite education was quite counter to this. It was libertarian education.
The conflicts about what education ought to be go right back through the early Enlightenment. There are two striking images that I think capture the essence of the conflict. One view is that education should be like pouring water into a bucket. As we all know from our own experiences, the brain is a pretty leaky bucket, so you can study for an exam on some topic in a course you're not interested in, learn enough to pass the exam, and a week later you've forgotten what the course was. The water has leaked out. But this approach to education does train you to be obedient and follow orders, even meaningless orders. The other type of education was described by one of the great founders of the modern higher education system, Wilhelm von Humboldt, a leading figure and founder of classical liberalism. He said education should be like laying out a string that the student follows in his own way. In other words, giving a general structure in which the learner—whether it's a child or an adult—will explore the world in their own creative, individual, independent fashion. Developing, not only acquiring knowledge. Learning how to learn.
That's the model you do find in a good scientific university. So if you're at MIT, a physics course is not a matter of pouring water into a bucket. This was described nicely by one of the great modern physicists, Victor Weisskopf, who died some years ago. When students would ask him what his course would cover, he would say, "It doesn't matter what we cover. It matters what you discover." In other words, if you can learn how to discover, then it doesn't matter what the subject matter is. You will use that talent elsewhere. That's essentially Humboldt's conception of education.
I should say that I learned about this not from books but from experience. I was in a Deweyite experimental school. That was the way things worked. It seemed very natural. I only read about it later.
The battle over education has been going on for quite some time now. The 1960s were a major period of agitation, activism, exploration, and they had a major civilizing effect on the society: civil rights, women's rights, a whole range of things. But for elites, it was a dangerous time because it had too much of a civilizing effect on the society. People were questioning authority, wanting to know answers, not just accepting everything that was handed down. There was an "excess of democracy." 
Looking for answers—that's frightening. There was an immediate backlash in the 1970s, and we're still living with the results. All of this is well documented. Two of the striking documents, which I think are very much worth reading, from opposite ends of the spectrum, are, on the Right, the Powell memorandum and, on what's called the Left, the Trilateral Commission report.
Lewis Powell was a corporate lobbyist for the tobacco industry who was very close to Nixon, who later appointed him to the Supreme Court. In 1971, he wrote a memorandum to the Chamber of Commerce, the main business lobby. It was supposed to be secret but it leaked. It's quite interesting reading, not only for the content but also because of the style, which is pretty typical of business literature and of totalitarian culture in general. It reads a little like NSC-68. The whole society is crumbling, everything is being lost. The universities are being taken over by followers of Herbert Marcuse. The media and the government have been taken over by the Left. Ralph Nader is destroying the private economy, and so on. Businessmen are the most persecuted element in the society, but we don't have to accept it, Powell said. We don't have to let these crazy people destroy everything. We have the wealth. We're the trustees of the universities. We're the people who own the media. We don't have to let all this happen. We can get together and use our power to force things in the direction that we want—of course he used nice terms such as democracy and freedom.
It is such a grotesque caricature, you have to wonder what lunacy could allow people to think like this. But it's normal. Like a three-year-old who doesn't get his way, if you think you ought to own everything and you've lost anything, everything is gone. That's very much the attitude of those who are accustomed to power and believe they have a right to power.
At the other end of the spectrum, you have the Trilateral Commission report, The Crisis of Democracy, written by liberal internationalists, Carter administration liberals, basically. They were concerned about what they called the failure of the "institutions which have played the major role in the indoctrination of the young." The young are not being properly indoctrinated by the schools, the churches. We can see that from the pressures for too much democracy. And we have to do something about it. It's not very different from Powell's memorandum. It's a little more nuanced, but it's essentially the same idea.
Too much freedom, too much democracy, not enough indoctrination—how do you deal with that? In the educational system, you move toward more control, more indoctrination, cutting back on the dangerous experiments with freedom and independence. That's what we've seen. These shifts correspond to the period when corporatization of the universities began to take place, with a sharp rise in managerial structures and a "bottom line" approach to education, and also when tuitions start to rise. The tuition problem has become so huge that it's on the front pages now. Student debt is on the scale of credit-card debt and by now it probably exceeds it. Students are burdened by huge debts. The laws have been changed so there's no way out—no bankruptcy, no escape. So you're trapped for life. That's quite a technique of indoctrination and control.
There's no economic basis for rising tuition costs. In the 1950s, our society was much poorer, but education was essentially free. The GI bill, was, of course, selective—it was for whites, not blacks, mostly men, not women—but it did offer free education to a huge part of the population that never would have gotten to college otherwise. More broadly, tuition was very low by current standards. It was a great help to the economy, incidentally. The 1950s and the 1960s were the decades of the greatest economic growth in history, and the newly educated population was a significant part of that story.
Now we're a much richer society than we were in the 1950s. Productivity has increased a lot. There's way more wealth. So it's ludicrous to think that education can't be funded. The same conclusion can be drawn by looking at other countries. Take, say, Mexico. It's a poor country. It has quite a decent higher education system. The quality is high. Teacher salaries are low by our standards, but the system is quite respectable. And it's free. Actually, the government did try some years ago to add a small tuition, but there was a national student strike and the government backed down. So education in this poor country is still free. The same is true in rich countries such as Germany and Finland, which has the best education system in the world by many measures. Education in these countries is free—or virtually free. If you look at the percentage of our gross domestic product that would be required to provide free higher education, it's very slight. So it's very hard to argue that there are any fundamental economic reasons for rising tuition costs. But it does have the effect of control and indoctrination.
Look at K-to-12 education, kindergarten through high school. Policies like No Child Left Behind under Bush and Race to the Top under Obama, despite what they may claim, basically require schools to teach to the test. They control teachers and make sure that they don't move in independent directions, a step toward imposing a business model, as in the colleges. Anyone who has any experience with the K-to-12 system knows how this works. Students are required to conform, to memorize to pass the next test. And there are punitive measures to keep teachers in line. If the students don't get a high-enough grade on the test—which could mean they're too creative and independent—then the teacher is in trouble. So they are forced to conform to this system.
Meanwhile, the basic problems with the educational system are never addressed. It's just way underfunded. Class sizes are too large. Diane Ravitch, formerly a conservative education critic who is now very critical of the current system and very knowledgeable, recently did some comparative work on the Finnish educational system, which gets all the best records in the world. She showed that one of the major differences is that teachers are respected in Finland. Teaching is considered a respected profession. Good people go into the field. They put energy and initiative into their work. They're given a good deal of freedom to experiment, explore, let students search on their own.
In Science, the journal of the American Association for the Advancement of Science, Bruce Alberts, a biochemist, had a series of editorials on science education. What he points out is quite interesting. He says science education is increasingly being designed with the effect of killing any interest in science. If you are in college, maybe you have to memorize a bunch of enzymes or something. If you are in elementary school, you memorize the periodic table. When you study the discovery of DNA, you're just taught what scientists already discovered. You memorize the fact that DNA is a double helix. Science is being taught in a way that kills any joy in science, gives you no sense of what discovery is. It's the opposite of Weisskopf's view that it matters what you discover, not what you cover.
Alberts gives some nice examples of alternatives that do work. In one kindergarten class, each kid was given a dish with a mixture of pebbles, shells, and seeds, and asked, "How do we know if something is a seed?"19 So the class began with what they called a "scientific conference." The kids got together and discussed the various ways in which you might be able to figure out what a seed is. The kids were guided by the teacher, so if things went off in some wrong direction, the teacher could step in. But it's essentially laying down the string. Here's your task. Figure it out. Over time, they did figure it out. They ran some experiments, tried out new ideas, interacted. At the end of this particular program each kid was given a magnifying glass. They cut open the seeds and discovered what the embryo is that gives the seed its energy and differentiates it from a pebble. Those kids learned something. Not only did they learn something about seeds, which doesn't matter that much, they learned what it is to discover something, why it's fun and exciting, why you should try it somewhere else, why you should be puzzled and inquire.
That can be done at any level of education. A friend of mine who teaches sixth grade described to me once how she had taught her students about the American Revolution. A couple of weeks before they got to that assignment, she started acting very harshly, issuing orders and commands, making the kids to do all kinds of things they didn't want to do. They got pretty upset, and they wanted to do something about it. They started to get together and protest. By the time it got to the right point, she opened the lesson on the American Revolution. She said, "Okay, now you can see why people rebel." And they understood why you would. That's the type of creative teaching that doesn't pass some standardized test necessarily, but it allows children to learn. That can be done at any level, from kindergarten to graduate school, in any subject—history, science, whatever it may be.
So those are the two concepts. And it's pretty clear which way the educational system is being pressed—and I think there's a reason why. We've got to educate people to keep them from our throats, as Emerson put it a long time ago. At the K-to-12 level, there is now an effort to destroy the public educational system. That's essentially what charter schools are about. They don't have any better outcomes. They feed at the public trough, the public pays for them, but they're essentially out of the public system and under much more private control, essentially privatized. It's destroying the ethic of the public education system. The ethic of that system is solidarity. You have a public education system because you're supposed to care whether children you don't know and have nothing to do with have the opportunity to go to school. That's social solidarity, but that's very dangerous—the opposite of atomization.
My feeling is that Social Security is under attack for the same reasons. There's no economic reason. It's in very good shape. With a little tinkering, it could go on indefinitely. But it's always listed as one of the big problems. We've got to do something about Social Security. I think the issue is the same: it's a system based on the concept that you should care about others, that you should care whether elderly people you don't know can live decent lives. You can't have that sort of thing. If a widow somewhere doesn't have food, it's her problem. She married the wrong husband or didn't invest properly. In a society in which everyone is out just for themselves, you don't pay attention to anyone else.
Ron Paul was asked at a Republican presidential debate what if "something terrible happens" to some guy who has no health insurance? What do you do? He said, "That's what freedom is all about: taking your own risks." Actually, when the moderator pushed back on this, he backed off and he said that people without health insurance would be taken care of by their families or their church. Then Rand Paul—this is more interesting—said national health insurance is slavery. He said, I'm a physician, and if there's national health insurance, the government is forcing me to take care of somebody who is ill. Why should I be a slave to the state? Here we're getting capitalist pathology in its most extreme, lunatic form. It is the opposite of solidarity, mutual support, mutual help.
Is it a form of social Darwinism?
I wouldn't even call it social Darwinism. That's too sophisticated. It's just, I'm out for myself, nobody else—and that's the way it ought to be. There was a recent study done at Harvard University's Institute of Politics on attitudes of young people from ages eighteen to twenty-nine. It was pretty striking. There's a lot of commitment to what in the United States are called libertarian ideas. Libertarian in the United States is pretty close to totalitarian. If you really think through what are called libertarian concepts, they basically say that we're going to hand over decision making to concentrations of private power and then everybody will be free. I'm not saying the people who advocate it intend that, but if you think it through, that's the consequence, plus the breaking down of social bonds. A lot of young people are attracted to that. For example, less than half of the people in the Harvard survey felt that the government should provide health insurance or "basic necessities, such as food and shelter" to those in need who cannot afford them.24
When people talk about the government in the United States, they're talking about some alien force. Hatred of democracy is so deeply embedded in the doctrinal system that you don't think of the government as your instrument. It's some alien instrument. It's taken a lot of work to make people hate democracy that much. In a democratic society, to the extent that it's a democratic society, the government is you. It's your decisions. But the government here is depicted as something that's attacking us, not our instrument to do what we decide.
Actually, one of the most frightening statistics for the Harvard survey has to do with the environment. Only 28 percent think that the "government should do more to curb climate change, even at the expense of economic growth." If that continues, that's a death sentence for the species. But it's the anticipated result of the major attack on social solidarity, on participation, on interaction, and on the fundamentals of democracy.
April 15, the day when you pay your taxes, gives you a good index of how democracy is functioning. If democracy were functioning effectively, April 15 would be a day of celebration. That's a day on which we get together to contribute to implementing the policies that we've decided on. That's what April 15 ought to be. Here it's a day of mourning. This alien force is coming to steal your hard-earned money from you. That indicates an extreme contempt for democracy. And it's natural that a business-run society and doctrinal system should try to inculcate that belief.